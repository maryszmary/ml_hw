{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный Байес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирую нужные библиотеки и загружаю датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "messages = pandas.read_csv('SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        message\n",
      "label                                                          \n",
      "ham   count                                                4825\n",
      "      unique                                               4516\n",
      "      top                                Sorry, I'll call later\n",
      "      freq                                                   30\n",
      "spam  count                                                 747\n",
      "      unique                                                653\n",
      "      top     Please call our customer service representativ...\n",
      "      freq                                                    4\n"
     ]
    }
   ],
   "source": [
    "print(messages.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Как показывает группировка данных по классам, датасет не сбалансированный, так как спама сильно больше, чем не спама. Если всем новым наблюдениям присваивать класс ham, то точность будет достаточно высокой, но с точки зрения задачи классификации спами это плохое решение, так как такой классификатор вообще не будет отсеивать спам. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Балансирую данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam = messages[messages['label'] == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham = messages[messages['label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825\n"
     ]
    }
   ],
   "source": [
    "print(len(ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n"
     ]
    }
   ],
   "source": [
    "less_ham = ham.sample(n=len(spam))\n",
    "print(len(less_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        message\n",
      "label                                                          \n",
      "ham   count                                                 747\n",
      "      unique                                                732\n",
      "      top                                Sorry, I'll call later\n",
      "      freq                                                    4\n",
      "spam  count                                                 747\n",
      "      unique                                                653\n",
      "      top     Please call our customer service representativ...\n",
      "      freq                                                    4\n"
     ]
    }
   ],
   "source": [
    "balanced = pandas.concat([less_ham, spam])\n",
    "print(balanced.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соотношение 1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный Байес, фичи – слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаю модель с дефолтными характеристиками: убираем знаки препинания, не лемматизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gettin',\n",
       " 'fyi',\n",
       " 'breathe1',\n",
       " 'text',\n",
       " 'hoody',\n",
       " 'pages',\n",
       " 'panther',\n",
       " '08712101358',\n",
       " 'chatlines',\n",
       " 'smiling']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 рандомных токенов\n",
    "list(bow.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, по дефолту ничего не лемматизируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963 0.011\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем оставить знаки препинания, используя токенизатор word_tokenize. Он оставляет знаки препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954 0.015\n"
     ]
    }
   ],
   "source": [
    "def tokenize_leave_punct(text): return word_tokenize(text.lower())\n",
    "\n",
    "bow = CountVectorizer(tokenizer=tokenize_leave_punct)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со знаками препинания получилось хуже. Правда, эксперимент был не совсем чистым, потому что токенизаторы вообще разные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь попробуем лемматизировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    noun = lmtzr.lemmatize(word)\n",
    "    verb = lmtzr.lemmatize(word, 'v')\n",
    "    if verb != word:\n",
    "        return verb\n",
    "    return noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention!\n",
    "Кусочек кода в клетке выше позаимствован у Тани Гавриловой после того, как мы с ней обсудили следующую проблему (обнаруженную ей). У лемматизатора ворднетлемматайзера nltk есть аргумент, отвечающий за часть речи. По дефолту он считает, что ему подали существительное, и лемматизирует его как существительное. Соответственно, результатом для слова leaves будет leaf, а для going так и останется going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leaf'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('going')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, если подать ему аргумент 'v', всё будет иначе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leave'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('leaves', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr.lemmatize('going', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сообветственно, чтобы лемматизация была адекватной, нужно сначала использовать POS тэггер, его выдачу преобразовывать и подавать на вход лемматизатору. У nltk есть pos_tag, но те тэги, который она выдаёт, отличаются от тэгов, которые принимает на вход лемматизатор, причём их много и они разные. Соответственно, можно со всем этим долго возиться и бомбить на тему того, почему нельзя было разу сделать нормальный лемматизатор. А можно воспользоваться тем костылём, что если лемматизация словоформы как глагола даёт какой-то результат, отличный от самой словоформы, то, видимо, это был глагол (или существительное во множественном числе, которое лемматизируется так же). Проблему с leaves это всё же решит плохо, но leaves больше похоже на единичный случай."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    return [lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954 0.012\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(tokenizer=tokenize_lemmatize)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты практически не изменились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955 0.014\n"
     ]
    }
   ],
   "source": [
    "def tokenize_lemmatize(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    return [lemmatize(word) for word in text if word not in '!?,.\":;']\n",
    "\n",
    "bow = CountVectorizer(tokenizer=tokenize_lemmatize)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Без знаков препинания чуууть-чуть получше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробую убирать стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944 0.014\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def tokenize_lemmatize(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    text = [lemmatize(word) for word in text if word not in '!?,.\":;']\n",
    "    return [word for word in text if word not in STOPWORDS]\n",
    "\n",
    "bow = CountVectorizer(tokenizer=tokenize_lemmatize)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значительно хуже. :/\n",
    "\n",
    "\n",
    "В общем, кажется, лучше не лемматизировать и убирать знаки препинания (или просто дефолтный токенизатор CountVectorizer работает настолько лучше). А что если использовать его и убирать стоп-слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 0.018\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(stop_words=STOPWORDS)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хм, нет, убирать стоп-слова было явно плохой идеей. Хотя встроенный токенизатор и правда работает лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробую дефолтные настройки и ограничивать df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверху:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964 0.011\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(max_df=0.3)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потрясающе, стало лучше, чем дефолт! (Но не сильно).\n",
    "Я попробовала несколько разных порогов, лучше всего работает в районе 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снизу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965 0.01\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(min_df=2)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего работает порог 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И сверху, и снизу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963 0.01\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(min_df=2, max_df=0.3)\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так хуже о_О."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробую TfIdfVectorizer с дефолтными настройками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964 0.009\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(balanced['message'])\n",
    "tfidf_transformer = TfidfTransformer().fit(counts)\n",
    "tfidf = tfidf_transformer.transform(counts)\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(tfidf, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, tfidf, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, очень даже неплохие результаты. А что если добавить чего-нибудь успешного из прошлых шагов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957 0.015\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=2)\n",
    "counts = count_vect.fit_transform(balanced['message'])\n",
    "tfidf_transformer = TfidfTransformer().fit(counts)\n",
    "tfidf = tfidf_transformer.transform(counts)\n",
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(tfidf, balanced['label'])\n",
    "cv_results = cross_val_score(naive_model, tfidf, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень-то. Ну ладно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В общем, лучше всего получилось, кажется, при дефолтных настройках CountVectorizer с нижним ограничением на количество вхождений 2 и с применением TfidfTransformer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья решений и рандомный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bow = CountVectorizer()\n",
    "bow.fit_transform(balanced['message'])\n",
    "bowed_messages = bow.transform(balanced['message'])\n",
    "\n",
    "tree = DecisionTreeClassifier(min_samples_split=5)\n",
    "tree.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(tree, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений работает значительно хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936 0.018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(bowed_messages, balanced['label'])\n",
    "cv_results = cross_val_score(model, bowed_messages, balanced['label'], cv=10, scoring='accuracy')\n",
    "print(round(cv_results.mean(), 3), round(cv_results.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Рандомный лес"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
